{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99aeffad",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'scipy.sparse' has no attribute 'linalg'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mjoblib\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m mean_absolute_error, mean_squared_error\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m clone\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# ---------- Paths ----------\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Infosys\\Project\\myenv\\Lib\\site-packages\\sklearn\\__init__.py:73\u001b[39m\n\u001b[32m     62\u001b[39m \u001b[38;5;66;03m# `_distributor_init` allows distributors to run custom init code.\u001b[39;00m\n\u001b[32m     63\u001b[39m \u001b[38;5;66;03m# For instance, for the Windows wheel, this is used to pre-load the\u001b[39;00m\n\u001b[32m     64\u001b[39m \u001b[38;5;66;03m# vcomp shared library runtime for OpenMP embedded in the sklearn/.libs\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     67\u001b[39m \u001b[38;5;66;03m# later is linked to the OpenMP runtime to make it possible to introspect\u001b[39;00m\n\u001b[32m     68\u001b[39m \u001b[38;5;66;03m# it and importing it first would fail if the OpenMP dll cannot be found.\u001b[39;00m\n\u001b[32m     69\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# noqa: F401 E402\u001b[39;00m\n\u001b[32m     70\u001b[39m     __check_build,\n\u001b[32m     71\u001b[39m     _distributor_init,\n\u001b[32m     72\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m clone  \u001b[38;5;66;03m# noqa: E402\u001b[39;00m\n\u001b[32m     74\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_show_versions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m show_versions  \u001b[38;5;66;03m# noqa: E402\u001b[39;00m\n\u001b[32m     76\u001b[39m _submodules = [\n\u001b[32m     77\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mcalibration\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     78\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mcluster\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    114\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mcompose\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    115\u001b[39m ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Infosys\\Project\\myenv\\Lib\\site-packages\\sklearn\\base.py:20\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexceptions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m InconsistentVersionWarning\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_metadata_requests\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _MetadataRequester, _routing_enabled\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_missing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m is_scalar_nan\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_param_validation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m validate_parameter_constraints\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_repr_html\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ReprHTMLMixin, _HTMLDocumentationLinkMixin\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Infosys\\Project\\myenv\\Lib\\site-packages\\sklearn\\utils\\__init__.py:9\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m metadata_routing\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_bunch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Bunch\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_chunking\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m gen_batches, gen_even_slices\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# Make _safe_indexing importable from here for backward compat as this particular\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# helper is considered semi-private and typically very useful for third-party\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# libraries that want to comply with scikit-learn's estimator API. In particular,\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# _safe_indexing was included in our public API documentation despite the leading\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# `_` in its name.\u001b[39;00m\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_indexing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     17\u001b[39m     _safe_indexing,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[32m     18\u001b[39m     resample,\n\u001b[32m     19\u001b[39m     shuffle,\n\u001b[32m     20\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Infosys\\Project\\myenv\\Lib\\site-packages\\sklearn\\utils\\_chunking.py:11\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_config\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_config\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_param_validation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Interval, validate_params\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mchunk_generator\u001b[39m(gen, chunksize):\n\u001b[32m     15\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Chunk generator, ``gen`` into lists of length ``chunksize``. The last\u001b[39;00m\n\u001b[32m     16\u001b[39m \u001b[33;03m    chunk may have a length less than ``chunksize``.\"\"\"\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Infosys\\Project\\myenv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:17\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscipy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msparse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m csr_matrix, issparse\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_config\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m config_context, get_config\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mvalidation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _is_arraylike_not_scalar\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mInvalidParameterError\u001b[39;00m(\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[32m     21\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Custom exception to be raised when the parameter of a class/method/function\u001b[39;00m\n\u001b[32m     22\u001b[39m \u001b[33;03m    does not have a valid type or value.\u001b[39;00m\n\u001b[32m     23\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Infosys\\Project\\myenv\\Lib\\site-packages\\sklearn\\utils\\validation.py:21\u001b[39m\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_config \u001b[38;5;28;01mas\u001b[39;00m _get_config\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexceptions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DataConversionWarning, NotFittedError, PositiveSpectrumWarning\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_array_api\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _asarray_with_order, _is_numpy_namespace, get_namespace\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdeprecation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _deprecate_force_all_finite\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfixes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ComplexWarning, _preserve_dia_indices_dtype\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Infosys\\Project\\myenv\\Lib\\site-packages\\sklearn\\utils\\_array_api.py:20\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexternals\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m array_api_extra \u001b[38;5;28;01mas\u001b[39;00m xpx\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexternals\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01marray_api_compat\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m numpy \u001b[38;5;28;01mas\u001b[39;00m np_compat\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfixes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m parse_version\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# TODO: complete __all__\u001b[39;00m\n\u001b[32m     23\u001b[39m __all__ = [\u001b[33m\"\u001b[39m\u001b[33mxpx\u001b[39m\u001b[33m\"\u001b[39m]  \u001b[38;5;66;03m# we import xpx here just to re-export it, need this to appease ruff\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Infosys\\Project\\myenv\\Lib\\site-packages\\sklearn\\utils\\fixes.py:73\u001b[39m\n\u001b[32m     71\u001b[39m \u001b[38;5;66;03m# TODO: Remove when Scipy 1.12 is the minimum supported version\u001b[39;00m\n\u001b[32m     72\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m sp_base_version >= parse_version(\u001b[33m\"\u001b[39m\u001b[33m1.12.0\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m     _sparse_linalg_cg = \u001b[43mscipy\u001b[49m\u001b[43m.\u001b[49m\u001b[43msparse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinalg\u001b[49m.cg\n\u001b[32m     74\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     76\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_sparse_linalg_cg\u001b[39m(A, b, **kwargs):\n",
      "\u001b[31mAttributeError\u001b[39m: module 'scipy.sparse' has no attribute 'linalg'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.base import clone\n",
    "\n",
    "# ---------- Paths ----------\n",
    "model_paths = {\n",
    "    \"usage_cpu\": \"../backend/models/usage_cpu_best_model.pkl\",\n",
    "    \"usage_storage\": \"../backend/models/usage_storage_best_model.pkl\",\n",
    "    \"users_active\": \"../backend/models/users_active_best_model.pkl\",\n",
    "}\n",
    "\n",
    "model_paths_save = {\n",
    "    \"usage_cpu\": \"../backend/models/backtested_models/usage_cpu_best_model.pkl\",\n",
    "    \"usage_storage\": \"../backend/models/backtested_models/usage_storage_best_model.pkl\",\n",
    "    \"users_active\": \"../backend/models/backtested_models/users_active_best_model.pkl\",\n",
    "}\n",
    "\n",
    "data_path = \"../Data/models/enhanced_features.csv\"\n",
    "results_dir = \"./results/\"\n",
    "\n",
    "# ---------- Load data ----------\n",
    "df = pd.read_csv(data_path)\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "\n",
    "# ---------- Load models ----------\n",
    "models = {key: joblib.load(path) for key, path in model_paths.items()}\n",
    "\n",
    "# ---------- Metrics functions ----------\n",
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / np.maximum(y_true, 1e-8)))\n",
    "\n",
    "def bias(y_true, y_pred):\n",
    "    return np.mean(y_pred - y_true)\n",
    "\n",
    "# ---------- Rolling backtest & fine-tune ----------\n",
    "def rolling_backtest(df, target, model, window_size=30):\n",
    "    df = df.sort_values(\"date\").copy()\n",
    "    metrics_list = []\n",
    "\n",
    "    feature_cols = [c for c in df.columns if c not in [\"date\", \"usage_cpu\", \"usage_storage\", \"users_active\", \"unique_id\"]]\n",
    "\n",
    "    # Disable early stopping for small rolling windows\n",
    "    if hasattr(model, \"early_stopping_rounds\"):\n",
    "        model.set_params(early_stopping_rounds=None)\n",
    "\n",
    "    # Clone the model to avoid overwriting original\n",
    "    temp_model = clone(model)\n",
    "\n",
    "    for start in range(len(df) - window_size):\n",
    "        train = df.iloc[: start + window_size]\n",
    "        test = df.iloc[start + window_size : start + window_size + 1]\n",
    "\n",
    "        X_train, y_train = train[feature_cols], train[target]\n",
    "        X_test, y_test = test[feature_cols], test[target]\n",
    "\n",
    "        # Fine-tune model on training window\n",
    "        temp_model.fit(X_train, y_train)\n",
    "        y_pred = temp_model.predict(X_test)\n",
    "\n",
    "        # Metrics\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "        mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "        b = bias(y_test, y_pred)\n",
    "\n",
    "        metrics_list.append({\n",
    "            \"date\": test[\"date\"].iloc[0].strftime(\"%Y-%m-%d\"),\n",
    "            \"mae\": mae,\n",
    "            \"rmse\": rmse,\n",
    "            \"mape\": mape,\n",
    "            \"bias\": b\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(metrics_list), temp_model\n",
    "\n",
    "# ---------- Run backtest for all targets ----------\n",
    "all_metrics = {}\n",
    "\n",
    "for target, model in models.items():\n",
    "    print(f\"Backtesting {target}...\")\n",
    "    metrics_df, fine_tuned_model = rolling_backtest(df, target, model)\n",
    "\n",
    "    # Save fine-tuned model\n",
    "    joblib.dump(fine_tuned_model, model_paths_save[target])\n",
    "\n",
    "    # Save metrics\n",
    "    metrics_csv_path = f\"{results_dir}{target}_backtest_metrics.csv\"\n",
    "    metrics_df.to_csv(metrics_csv_path, index=False)\n",
    "\n",
    "    all_metrics[target] = metrics_df\n",
    "    print(f\"Saved metrics for {target} to {metrics_csv_path} and fine-tuned model updated.\")\n",
    "\n",
    "# ---------- Example: Forward Forecast (April) ----------\n",
    "from datetime import timedelta\n",
    "\n",
    "def forecast_future(df, target, model, days=30):\n",
    "    df = df.sort_values(\"date\").copy()\n",
    "    last_date = df[\"date\"].max()\n",
    "    hist_df = df.copy()\n",
    "    forecasts = []\n",
    "\n",
    "    feature_cols = [c for c in df.columns if c not in [\"date\", \"usage_cpu\", \"usage_storage\", \"users_active\", \"unique_id\"]]\n",
    "\n",
    "    for i in range(days):\n",
    "        next_date = last_date + timedelta(days=i + 1)\n",
    "        new_row = hist_df.iloc[-1:].copy()\n",
    "        new_row[\"date\"] = next_date\n",
    "\n",
    "        # Update lags and rolling stats\n",
    "        for lag in [1,7,14]:\n",
    "            new_row[f\"{target}_lag_{lag}\"] = hist_df[target].iloc[-lag]\n",
    "        for win in [7,14]:\n",
    "            roll_vals = hist_df[target].iloc[-win:]\n",
    "            new_row[f\"{target}_roll_mean_{win}\"] = roll_vals.mean()\n",
    "            new_row[f\"{target}_roll_std_{win}\"] = roll_vals.std(ddof=0)\n",
    "\n",
    "        X_next = new_row[feature_cols]\n",
    "        pred = model.predict(X_next)[0]\n",
    "        new_row[target] = pred\n",
    "\n",
    "        forecasts.append({\"date\": next_date.strftime(\"%Y-%m-%d\"), \"predicted\": float(pred)})\n",
    "        hist_df = pd.concat([hist_df, new_row], ignore_index=True)\n",
    "\n",
    "    return pd.DataFrame(forecasts)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a4ea7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu_forecast = forecast_future(df, \"usage_cpu\", models[\"usage_cpu\"], days=30)\n",
    "cpu_forecast.to_csv(\"./results/cpu_april_forecast.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9f23d69",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'scipy.sparse' has no attribute 'linalg'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      1\u001b[39m model_paths = {\n\u001b[32m      2\u001b[39m     \u001b[33m'\u001b[39m\u001b[33musage_storage\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33m../backend/models/backtested_models/usage_storage_best_model.pkl\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m      3\u001b[39m }\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m models = {name: \u001b[43mjoblib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m name, path \u001b[38;5;129;01min\u001b[39;00m model_paths.items()}\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# ------------------------------\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Forecast Function for April (Friend-like)\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# ------------------------------\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforecast_april_simulated\u001b[39m(model, target_col, df, horizon=\u001b[32m30\u001b[39m, variability_factor=\u001b[32m5\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Infosys\\Project\\myenv\\Lib\\site-packages\\joblib\\numpy_pickle.py:749\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(filename, mmap_mode, ensure_native_byte_order)\u001b[39m\n\u001b[32m    744\u001b[39m                 \u001b[38;5;28;01mreturn\u001b[39;00m load_compatibility(fobj)\n\u001b[32m    746\u001b[39m             \u001b[38;5;66;03m# A memory-mapped array has to be mapped with the endianness\u001b[39;00m\n\u001b[32m    747\u001b[39m             \u001b[38;5;66;03m# it has been written with. Other arrays are coerced to the\u001b[39;00m\n\u001b[32m    748\u001b[39m             \u001b[38;5;66;03m# native endianness of the host system.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m749\u001b[39m             obj = \u001b[43m_unpickle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    750\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    751\u001b[39m \u001b[43m                \u001b[49m\u001b[43mensure_native_byte_order\u001b[49m\u001b[43m=\u001b[49m\u001b[43mensure_native_byte_order\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    752\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    753\u001b[39m \u001b[43m                \u001b[49m\u001b[43mmmap_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalidated_mmap_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    754\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    756\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m obj\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Infosys\\Project\\myenv\\Lib\\site-packages\\joblib\\numpy_pickle.py:626\u001b[39m, in \u001b[36m_unpickle\u001b[39m\u001b[34m(fobj, ensure_native_byte_order, filename, mmap_mode)\u001b[39m\n\u001b[32m    624\u001b[39m obj = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    625\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m626\u001b[39m     obj = \u001b[43munpickler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    627\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m unpickler.compat_mode:\n\u001b[32m    628\u001b[39m         warnings.warn(\n\u001b[32m    629\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mThe file \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m has been generated with a \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    630\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mjoblib version less than 0.10. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    633\u001b[39m             stacklevel=\u001b[32m3\u001b[39m,\n\u001b[32m    634\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\Python313\\Lib\\pickle.py:1256\u001b[39m, in \u001b[36m_Unpickler.load\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1254\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEOFError\u001b[39;00m\n\u001b[32m   1255\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, bytes_types)\n\u001b[32m-> \u001b[39m\u001b[32m1256\u001b[39m         \u001b[43mdispatch\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1257\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m _Stop \u001b[38;5;28;01mas\u001b[39;00m stopinst:\n\u001b[32m   1258\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m stopinst.value\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\Python313\\Lib\\pickle.py:1581\u001b[39m, in \u001b[36m_Unpickler.load_stack_global\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1579\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(name) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mstr\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(module) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mstr\u001b[39m:\n\u001b[32m   1580\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m UnpicklingError(\u001b[33m\"\u001b[39m\u001b[33mSTACK_GLOBAL requires str\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1581\u001b[39m \u001b[38;5;28mself\u001b[39m.append(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfind_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\Python313\\Lib\\pickle.py:1622\u001b[39m, in \u001b[36m_Unpickler.find_class\u001b[39m\u001b[34m(self, module, name)\u001b[39m\n\u001b[32m   1620\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m _compat_pickle.IMPORT_MAPPING:\n\u001b[32m   1621\u001b[39m         module = _compat_pickle.IMPORT_MAPPING[module]\n\u001b[32m-> \u001b[39m\u001b[32m1622\u001b[39m \u001b[38;5;28;43m__import__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1623\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.proto >= \u001b[32m4\u001b[39m:\n\u001b[32m   1624\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _getattribute(sys.modules[module], name)[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Infosys\\Project\\myenv\\Lib\\site-packages\\sklearn\\__init__.py:73\u001b[39m\n\u001b[32m     62\u001b[39m \u001b[38;5;66;03m# `_distributor_init` allows distributors to run custom init code.\u001b[39;00m\n\u001b[32m     63\u001b[39m \u001b[38;5;66;03m# For instance, for the Windows wheel, this is used to pre-load the\u001b[39;00m\n\u001b[32m     64\u001b[39m \u001b[38;5;66;03m# vcomp shared library runtime for OpenMP embedded in the sklearn/.libs\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     67\u001b[39m \u001b[38;5;66;03m# later is linked to the OpenMP runtime to make it possible to introspect\u001b[39;00m\n\u001b[32m     68\u001b[39m \u001b[38;5;66;03m# it and importing it first would fail if the OpenMP dll cannot be found.\u001b[39;00m\n\u001b[32m     69\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# noqa: F401 E402\u001b[39;00m\n\u001b[32m     70\u001b[39m     __check_build,\n\u001b[32m     71\u001b[39m     _distributor_init,\n\u001b[32m     72\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m clone  \u001b[38;5;66;03m# noqa: E402\u001b[39;00m\n\u001b[32m     74\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_show_versions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m show_versions  \u001b[38;5;66;03m# noqa: E402\u001b[39;00m\n\u001b[32m     76\u001b[39m _submodules = [\n\u001b[32m     77\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mcalibration\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     78\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mcluster\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    114\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mcompose\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    115\u001b[39m ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Infosys\\Project\\myenv\\Lib\\site-packages\\sklearn\\base.py:20\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexceptions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m InconsistentVersionWarning\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_metadata_requests\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _MetadataRequester, _routing_enabled\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_missing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m is_scalar_nan\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_param_validation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m validate_parameter_constraints\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_repr_html\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ReprHTMLMixin, _HTMLDocumentationLinkMixin\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Infosys\\Project\\myenv\\Lib\\site-packages\\sklearn\\utils\\__init__.py:9\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m metadata_routing\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_bunch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Bunch\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_chunking\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m gen_batches, gen_even_slices\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# Make _safe_indexing importable from here for backward compat as this particular\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# helper is considered semi-private and typically very useful for third-party\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# libraries that want to comply with scikit-learn's estimator API. In particular,\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# _safe_indexing was included in our public API documentation despite the leading\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# `_` in its name.\u001b[39;00m\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_indexing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     17\u001b[39m     _safe_indexing,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[32m     18\u001b[39m     resample,\n\u001b[32m     19\u001b[39m     shuffle,\n\u001b[32m     20\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Infosys\\Project\\myenv\\Lib\\site-packages\\sklearn\\utils\\_chunking.py:11\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_config\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_config\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_param_validation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Interval, validate_params\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mchunk_generator\u001b[39m(gen, chunksize):\n\u001b[32m     15\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Chunk generator, ``gen`` into lists of length ``chunksize``. The last\u001b[39;00m\n\u001b[32m     16\u001b[39m \u001b[33;03m    chunk may have a length less than ``chunksize``.\"\"\"\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Infosys\\Project\\myenv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:17\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscipy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msparse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m csr_matrix, issparse\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_config\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m config_context, get_config\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mvalidation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _is_arraylike_not_scalar\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mInvalidParameterError\u001b[39;00m(\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[32m     21\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Custom exception to be raised when the parameter of a class/method/function\u001b[39;00m\n\u001b[32m     22\u001b[39m \u001b[33;03m    does not have a valid type or value.\u001b[39;00m\n\u001b[32m     23\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Infosys\\Project\\myenv\\Lib\\site-packages\\sklearn\\utils\\validation.py:21\u001b[39m\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_config \u001b[38;5;28;01mas\u001b[39;00m _get_config\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexceptions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DataConversionWarning, NotFittedError, PositiveSpectrumWarning\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_array_api\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _asarray_with_order, _is_numpy_namespace, get_namespace\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdeprecation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _deprecate_force_all_finite\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfixes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ComplexWarning, _preserve_dia_indices_dtype\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Infosys\\Project\\myenv\\Lib\\site-packages\\sklearn\\utils\\_array_api.py:20\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexternals\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m array_api_extra \u001b[38;5;28;01mas\u001b[39;00m xpx\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexternals\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01marray_api_compat\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m numpy \u001b[38;5;28;01mas\u001b[39;00m np_compat\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfixes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m parse_version\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# TODO: complete __all__\u001b[39;00m\n\u001b[32m     23\u001b[39m __all__ = [\u001b[33m\"\u001b[39m\u001b[33mxpx\u001b[39m\u001b[33m\"\u001b[39m]  \u001b[38;5;66;03m# we import xpx here just to re-export it, need this to appease ruff\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Infosys\\Project\\myenv\\Lib\\site-packages\\sklearn\\utils\\fixes.py:73\u001b[39m\n\u001b[32m     71\u001b[39m \u001b[38;5;66;03m# TODO: Remove when Scipy 1.12 is the minimum supported version\u001b[39;00m\n\u001b[32m     72\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m sp_base_version >= parse_version(\u001b[33m\"\u001b[39m\u001b[33m1.12.0\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m     _sparse_linalg_cg = \u001b[43mscipy\u001b[49m\u001b[43m.\u001b[49m\u001b[43msparse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinalg\u001b[49m.cg\n\u001b[32m     74\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     76\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_sparse_linalg_cg\u001b[39m(A, b, **kwargs):\n",
      "\u001b[31mAttributeError\u001b[39m: module 'scipy.sparse' has no attribute 'linalg'"
     ]
    }
   ],
   "source": [
    "\n",
    "model_paths = {\n",
    "    'usage_storage': '../backend/models/backtested_models/usage_storage_best_model.pkl',\n",
    "}\n",
    "\n",
    "models = {name: joblib.load(path) for name, path in model_paths.items()}\n",
    "\n",
    "# ------------------------------\n",
    "# Forecast Function for April (Friend-like)\n",
    "# ------------------------------\n",
    "def forecast_april_simulated(model, target_col, df, horizon=30, variability_factor=5):\n",
    "    \"\"\"\n",
    "    Forecast April recursively using last 3 months.\n",
    "    Simulate real fluctuations by extrapolating daily percentage changes.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    hist_df = df.copy()\n",
    "    last_date = hist_df['date'].max()\n",
    "\n",
    "    forecasts = []\n",
    "\n",
    "    for i in range(horizon):\n",
    "        next_date = last_date + timedelta(days=i + 1)\n",
    "        new_row = hist_df.iloc[-1:].copy()\n",
    "        new_row['date'] = next_date\n",
    "        new_row['month'] = next_date.month\n",
    "        new_row['dayofweek'] = next_date.dayofweek\n",
    "        new_row['dayofmonth'] = next_date.day\n",
    "        new_row['quarter'] = (next_date.month - 1) // 3 + 1\n",
    "        new_row['is_weekend'] = 1 if next_date.weekday() >= 5 else 0\n",
    "\n",
    "        # Propagate lag features with small relative daily change\n",
    "        for lag in [1, 7, 14]:\n",
    "            if len(hist_df) >= lag:\n",
    "                prev_val = hist_df[target_col].iloc[-lag]\n",
    "                pct_change = np.random.normal(0, variability_factor)  # +/- 3% daily fluctuation\n",
    "                new_row[f\"{target_col}_lag_{lag}\"] = prev_val * (1 + pct_change)\n",
    "            else:\n",
    "                new_row[f\"{target_col}_lag_{lag}\"] = hist_df[target_col].mean()\n",
    "\n",
    "        # Propagate rolling features similarly\n",
    "        for win in [7, 14]:\n",
    "            if len(hist_df) >= win:\n",
    "                prev_window = hist_df[target_col].iloc[-win:]\n",
    "                pct_changes = np.random.normal(0, variability_factor, size=win)\n",
    "                adjusted_window = prev_window * (1 + pct_changes)\n",
    "                new_row[f\"{target_col}_roll_mean_{win}\"] = adjusted_window.mean()\n",
    "                new_row[f\"{target_col}_roll_std_{win}\"] = adjusted_window.std(ddof=0)\n",
    "            else:\n",
    "                new_row[f\"{target_col}_roll_mean_{win}\"] = hist_df[target_col].mean()\n",
    "                new_row[f\"{target_col}_roll_std_{win}\"] = hist_df[target_col].std(ddof=0)\n",
    "\n",
    "        # Predict\n",
    "        feature_cols = [col for col in hist_df.columns if col not in ['date', 'usage_cpu', 'usage_storage', 'users_active', 'unique_id']]\n",
    "        X_next = new_row[feature_cols]\n",
    "        pred = model.predict(X_next)[0]\n",
    "        new_row[target_col] = pred\n",
    "\n",
    "        forecasts.append({'date': next_date.strftime('%Y-%m-%d'), 'predicted': float(pred)})\n",
    "\n",
    "        hist_df = pd.concat([hist_df, new_row], ignore_index=True)\n",
    "\n",
    "    return forecasts\n",
    "\n",
    "# ------------------------------\n",
    "# Example Usage\n",
    "# ------------------------------\n",
    "encoded_insights = pd.read_csv('../Data/models/enhanced_features.csv')\n",
    "\n",
    "april_forecast_cpu = forecast_april_simulated(models['usage_storage'], 'usage_storage', encoded_insights, horizon=30)\n",
    "\n",
    "for f in april_forecast_cpu:\n",
    "    print(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96a07826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtesting usage_storage...\n",
      "Saved metrics for usage_storage to ./results/usage_storage_backtest_metrics.csv and fine-tuned model updated.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.base import clone\n",
    "\n",
    "# ---------- Paths ----------\n",
    "model_paths = {\n",
    "    \"usage_storage\": \"../backend/models/usage_storage_best_enhanced_fixed_model.pkl\"\n",
    "}\n",
    "\n",
    "model_paths_save = {\n",
    "    \"usage_storage\": \"../backend/models/backtested_models/usage_storage_best_e_model.pkl\",\n",
    "}\n",
    "\n",
    "data_path = \"../Data/models/enhanced_features.csv\"\n",
    "results_dir = \"./results/\"\n",
    "\n",
    "# ---------- Load data ----------\n",
    "df = pd.read_csv(data_path)\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "\n",
    "# ---------- Load models ----------\n",
    "models = {key: joblib.load(path) for key, path in model_paths.items()}\n",
    "\n",
    "# ---------- Metrics functions ----------\n",
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / np.maximum(y_true, 1e-8)))\n",
    "\n",
    "def bias(y_true, y_pred):\n",
    "    return np.mean(y_pred - y_true)\n",
    "\n",
    "# ---------- Rolling backtest & fine-tune ----------\n",
    "def rolling_backtest(df, target, model, window_size=30):\n",
    "    df = df.sort_values(\"date\").copy()\n",
    "    metrics_list = []\n",
    "\n",
    "    feature_cols = [c for c in df.columns if c not in [\"date\", \"usage_cpu\", \"usage_storage\", \"users_active\", \"unique_id\"]]\n",
    "\n",
    "    # Disable early stopping for small rolling windows\n",
    "    if hasattr(model, \"early_stopping_rounds\"):\n",
    "        model.set_params(early_stopping_rounds=None)\n",
    "\n",
    "    # Clone the model to avoid overwriting original\n",
    "    temp_model = clone(model)\n",
    "\n",
    "    for start in range(len(df) - window_size):\n",
    "        train = df.iloc[: start + window_size]\n",
    "        test = df.iloc[start + window_size : start + window_size + 1]\n",
    "\n",
    "        X_train, y_train = train[feature_cols], train[target]\n",
    "        X_test, y_test = test[feature_cols], test[target]\n",
    "\n",
    "        # Fine-tune model on training window\n",
    "        temp_model.fit(X_train, y_train)\n",
    "        y_pred = temp_model.predict(X_test)\n",
    "\n",
    "        # Metrics\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "        mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "        b = bias(y_test, y_pred)\n",
    "\n",
    "        metrics_list.append({\n",
    "            \"date\": test[\"date\"].iloc[0].strftime(\"%Y-%m-%d\"),\n",
    "            \"mae\": mae,\n",
    "            \"rmse\": rmse,\n",
    "            \"mape\": mape,\n",
    "            \"bias\": b\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(metrics_list), temp_model\n",
    "\n",
    "# ---------- Run backtest for all targets ----------\n",
    "all_metrics = {}\n",
    "\n",
    "for target, model in models.items():\n",
    "    print(f\"Backtesting {target}...\")\n",
    "    metrics_df, fine_tuned_model = rolling_backtest(df, target, model)\n",
    "\n",
    "    # Save fine-tuned model\n",
    "    joblib.dump(fine_tuned_model, model_paths_save[target])\n",
    "\n",
    "    # Save metrics\n",
    "    metrics_csv_path = f\"{results_dir}{target}_backtest_metrics.csv\"\n",
    "    metrics_df.to_csv(metrics_csv_path, index=False)\n",
    "\n",
    "    all_metrics[target] = metrics_df\n",
    "    print(f\"Saved metrics for {target} to {metrics_csv_path} and fine-tuned model updated.\")\n",
    "\n",
    "# ---------- Example: Forward Forecast (April) ----------\n",
    "from datetime import timedelta\n",
    "\n",
    "def forecast_future(df, target, model, days=30):\n",
    "    df = df.sort_values(\"date\").copy()\n",
    "    last_date = df[\"date\"].max()\n",
    "    hist_df = df.copy()\n",
    "    forecasts = []\n",
    "\n",
    "    feature_cols = [c for c in df.columns if c not in [\"date\", \"usage_cpu\", \"usage_storage\", \"users_active\", \"unique_id\"]]\n",
    "\n",
    "    for i in range(days):\n",
    "        next_date = last_date + timedelta(days=i + 1)\n",
    "        new_row = hist_df.iloc[-1:].copy()\n",
    "        new_row[\"date\"] = next_date\n",
    "\n",
    "        # Update lags and rolling stats\n",
    "        for lag in [1,7,14]:\n",
    "            new_row[f\"{target}_lag_{lag}\"] = hist_df[target].iloc[-lag]\n",
    "        for win in [7,14]:\n",
    "            roll_vals = hist_df[target].iloc[-win:]\n",
    "            new_row[f\"{target}_roll_mean_{win}\"] = roll_vals.mean()\n",
    "            new_row[f\"{target}_roll_std_{win}\"] = roll_vals.std(ddof=0)\n",
    "\n",
    "        X_next = new_row[feature_cols]\n",
    "        pred = model.predict(X_next)[0]\n",
    "        new_row[target] = pred\n",
    "\n",
    "        forecasts.append({\"date\": next_date.strftime(\"%Y-%m-%d\"), \"predicted\": float(pred)})\n",
    "        hist_df = pd.concat([hist_df, new_row], ignore_index=True)\n",
    "\n",
    "    return pd.DataFrame(forecasts)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv (3.13.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
