{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1eabdc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c15e288",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../../Data/Processed/insights.csv\", parse_dates=[\"date\"])\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a912178d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(df, target_columns=['usage_cpu', 'usage_storage', 'users_active'],\n",
    "                   lags=[1, 7, 14], rolling_windows=[7, 14], fourier_k=3):\n",
    "    df = df.copy()\n",
    "\n",
    "    # Convert date\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "    # Sort by region, resource_type, and date\n",
    "    df = df.sort_values([\"region\", \"resource_type\", \"date\"])\n",
    "\n",
    "    # Numerically encode region and resource_type\n",
    "    df['region_encoded'] = df['region'].astype('category').cat.codes\n",
    "    df['resource_type_encoded'] = df['resource_type'].astype('category').cat.codes\n",
    "\n",
    "    # Create unique_id using encoded features\n",
    "    df['unique_id'] = df['region_encoded'].astype(str) + '_' + df['resource_type_encoded'].astype(str)\n",
    "\n",
    "    # Basic time features\n",
    "    df[\"dayofweek\"] = df[\"date\"].dt.dayofweek\n",
    "    df[\"month\"] = df[\"date\"].dt.month\n",
    "    df[\"weekofyear\"] = df[\"date\"].dt.isocalendar().week.astype(int)\n",
    "    df[\"dayofmonth\"] = df[\"date\"].dt.day\n",
    "    df[\"quarter\"] = df[\"date\"].dt.quarter\n",
    "    df[\"is_weekend\"] = (df[\"dayofweek\"] >= 5).astype(int)\n",
    "\n",
    "    # Create features for each target column\n",
    "    for target_col in target_columns:\n",
    "        # Lag features\n",
    "        for lag in lags:\n",
    "            df[f\"{target_col}_lag_{lag}\"] = df.groupby(\"unique_id\")[target_col].shift(lag)\n",
    "\n",
    "        # Rolling features (shifted by 1 to avoid data leakage)\n",
    "        for window in rolling_windows:\n",
    "            df[f\"{target_col}_roll_mean_{window}\"] = (\n",
    "                df.groupby(\"unique_id\")[target_col]\n",
    "                .shift(1)\n",
    "                .rolling(window=window, min_periods=1)\n",
    "                .mean()\n",
    "                .reset_index(0, drop=True)\n",
    "            )\n",
    "            df[f\"{target_col}_roll_std_{window}\"] = (\n",
    "                df.groupby(\"unique_id\")[target_col]\n",
    "                .shift(1)\n",
    "                .rolling(window=window, min_periods=1)\n",
    "                .std()\n",
    "                .reset_index(0, drop=True)\n",
    "            )\n",
    "\n",
    "    # Fourier features for cyclical patterns\n",
    "    for k in range(1, fourier_k + 1):\n",
    "        df[f\"sin_week_{k}\"] = np.sin(2 * np.pi * k * df[\"dayofweek\"] / 7)\n",
    "        df[f\"cos_week_{k}\"] = np.cos(2 * np.pi * k * df[\"dayofweek\"] / 7)\n",
    "\n",
    "    # Fill NaNs - first with group mean, then with forward/backward fill\n",
    "    numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "    df[numeric_cols] = df.groupby(\"unique_id\")[numeric_cols].transform(\n",
    "        lambda g: g.fillna(g.mean())\n",
    "    )\n",
    "\n",
    "    # Handle any remaining NaNs with forward/backward fill\n",
    "    df[numeric_cols] = df.groupby(\"unique_id\")[numeric_cols].transform(\n",
    "        lambda g: g.fillna(method=\"bfill\").fillna(method=\"ffill\")\n",
    "    )\n",
    "\n",
    "    df.drop(columns=['region','resource_type'], inplace = True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148ecbc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def features(filename):\n",
    "    # Load the data\n",
    "    df = pd.read_csv(filename)\n",
    "\n",
    "    print(\"Original data shape:\", df.shape)\n",
    "    print(\"Original columns:\", df.columns.tolist())\n",
    "    print(f\"Date range: {df['date'].min()} to {df['date'].max()}\")\n",
    "    # Fix: Combine region and resource_type row-wise before finding unique combinations\n",
    "    print(f\"Unique region-resource combinations: {len((df['region'].astype(str) + '_' + df['resource_type'].astype(str)).unique())}\")\n",
    "\n",
    "    # Create features\n",
    "    print(\"\\nCreating features...\")\n",
    "    df_features = create_features(\n",
    "        df,\n",
    "        target_columns=['usage_cpu', 'usage_storage', 'users_active', 'storage_efficiency'],\n",
    "        lags=[1, 7, 14],\n",
    "        rolling_windows=[7, 14],\n",
    "        fourier_k=3\n",
    "    )\n",
    "\n",
    "    print(f\"Enhanced data shape: {df_features.shape}\")\n",
    "\n",
    "    # Check for NaNs\n",
    "    nan_counts = df_features.isnull().sum()\n",
    "    total_nans = nan_counts.sum()\n",
    "\n",
    "    if total_nans > 0:\n",
    "        print(f\"âš ï¸  Found {total_nans} NaN values:\")\n",
    "        print(nan_counts[nan_counts > 0])\n",
    "    else:\n",
    "        print(\"âœ… No NaN values - all rows preserved!\")\n",
    "\n",
    "    # Show feature summary\n",
    "    print(f\"\\n=== FEATURES CREATED ===\")\n",
    "\n",
    "    # Time features\n",
    "    time_features = [col for col in df_features.columns if col in ['dayofweek', 'month', 'weekofyear', 'dayofmonth', 'quarter', 'is_weekend']]\n",
    "    print(f\"Time features: {time_features}\")\n",
    "\n",
    "    # Lag features\n",
    "    lag_features = [col for col in df_features.columns if '_lag_' in col]\n",
    "    print(f\"Lag features ({len(lag_features)}): {lag_features}\")\n",
    "\n",
    "    # Rolling features\n",
    "    rolling_features = [col for col in df_features.columns if '_roll_' in col]\n",
    "    print(f\"Rolling features ({len(rolling_features)}): {rolling_features}\")\n",
    "\n",
    "    # Fourier features\n",
    "    fourier_features = [col for col in df_features.columns if 'sin_week_' in col or 'cos_week_' in col]\n",
    "    print(f\"Fourier features: {fourier_features}\")\n",
    "\n",
    "    # Sample of enhanced data\n",
    "    print(f\"\\n=== SAMPLE DATA ===\")\n",
    "    sample_cols = ['date', 'unique_id', 'usage_cpu', 'usage_cpu_lag_1', 'usage_cpu_roll_mean_7', 'dayofweek', 'is_weekend']\n",
    "    available_cols = [col for col in sample_cols if col in df_features.columns]\n",
    "    print(df_features[available_cols].head(10))\n",
    "\n",
    "    # Save the enhanced dataset\n",
    "    output_file = 'enhanced_features.csv'\n",
    "    df_features.to_csv(output_file, index=False)\n",
    "    print(f\"\\nâœ… Enhanced dataset saved to '{output_file}'\")\n",
    "    print(f\"ðŸ“Š {df_features.shape[0]} rows Ã— {df_features.shape[1]} features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda8f2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/content/insights.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8134560d",
   "metadata": {},
   "outputs": [],
   "source": [
    "features(\"/content/insights.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv (3.13.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
