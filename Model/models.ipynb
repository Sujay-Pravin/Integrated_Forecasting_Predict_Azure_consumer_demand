{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ScwwjZ9Quxtm"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# ML Libraries\n",
        "import xgboost as xgb\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from 4sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "import joblib\n",
        "import pickle\n",
        "\n",
        "# Time Series Libraries\n",
        "try:\n",
        "    from statsmodels.tsa.arima.model import ARIMA\n",
        "    from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
        "except ImportError:\n",
        "    print(\"Warning: statsmodels not available - ARIMA/SARIMA models will be skipped\")\n",
        "\n",
        "# Deep Learning Libraries\n",
        "try:\n",
        "    import tensorflow as tf\n",
        "    from tensorflow.keras.models import Sequential\n",
        "    from tensorflow.keras.layers import LSTM, GRU, Dense, Dropout\n",
        "    from tensorflow.keras.callbacks import EarlyStopping\n",
        "    tf.random.set_seed(42)\n",
        "except ImportError:\n",
        "    print(\"Warning: TensorFlow not available - LSTM/GRU models will be skipped\")\n",
        "\n",
        "from datetime import datetime, timedelta\n",
        "import os\n",
        "\n",
        "class ForecastingPipeline:\n",
        "    def __init__(self, data_path):\n",
        "        self.data_path = data_path\n",
        "        self.models = {}\n",
        "        self.results = {}\n",
        "        self.target_columns = ['usage_cpu', 'usage_storage', 'users_active']\n",
        "        self.feature_columns = []\n",
        "\n",
        "        # Create directories for saving models\n",
        "        os.makedirs('models', exist_ok=True)\n",
        "        os.makedirs('results', exist_ok=True)\n",
        "        os.makedirs('top_models', exist_ok=True)\n",
        "\n",
        "        self.hyperparameter_results = {}  # Store hyperparameter search results\n",
        "\n",
        "    def load_and_prepare_data(self):\n",
        "        \"\"\"Load and prepare data for training\"\"\"\n",
        "        print(\"Loading and preparing data...\")\n",
        "        self.df = pd.read_csv(self.data_path)\n",
        "        self.df['date'] = pd.to_datetime(self.df['date'])\n",
        "        self.df = self.df.sort_values(['unique_id', 'date'])\n",
        "\n",
        "        # Define feature columns (exclude targets and non-feature columns)\n",
        "        exclude_cols = ['date', 'unique_id'] + self.target_columns\n",
        "        # Only select numeric columns for features\n",
        "        numeric_cols = self.df.select_dtypes(include=[np.number]).columns\n",
        "        self.feature_columns = [col for col in numeric_cols if col not in exclude_cols]\n",
        "\n",
        "        print(f\"Data loaded: {self.df.shape}\")\n",
        "        print(f\"Feature columns: {len(self.feature_columns)}\")\n",
        "        print(f\"Target columns: {self.target_columns}\")\n",
        "\n",
        "        return self.df\n",
        "\n",
        "    def create_train_val_test_split(self, df, train_ratio=0.7, val_ratio=0.2):\n",
        "        \"\"\"Create train/validation/test splits by unique_id\"\"\"\n",
        "        train_data, val_data, test_data = [], [], []\n",
        "\n",
        "        for unique_id in df['unique_id'].unique():\n",
        "            group_data = df[df['unique_id'] == unique_id].sort_values('date')\n",
        "            n = len(group_data)\n",
        "\n",
        "            train_end = int(n * train_ratio)\n",
        "            val_end = int(n * (train_ratio + val_ratio))\n",
        "\n",
        "            train_data.append(group_data.iloc[:train_end])\n",
        "            val_data.append(group_data.iloc[train_end:val_end])\n",
        "            test_data.append(group_data.iloc[val_end:])\n",
        "\n",
        "        train_df = pd.concat(train_data, ignore_index=True)\n",
        "        val_df = pd.concat(val_data, ignore_index=True)\n",
        "        test_df = pd.concat(test_data, ignore_index=True)\n",
        "\n",
        "        print(f\"Train: {len(train_df)} samples\")\n",
        "        print(f\"Validation: {len(val_df)} samples\")\n",
        "        print(f\"Test: {len(test_df)} samples\")\n",
        "\n",
        "        return train_df, val_df, test_df\n",
        "\n",
        "    def calculate_metrics(self, y_true, y_pred, model_name, target):\n",
        "        \"\"\"Calculate evaluation metrics\"\"\"\n",
        "        # Handle any NaN or infinite values\n",
        "        mask = ~(np.isnan(y_true) | np.isnan(y_pred) | np.isinf(y_true) | np.isinf(y_pred))\n",
        "        y_true_clean = y_true[mask]\n",
        "        y_pred_clean = y_pred[mask]\n",
        "\n",
        "        if len(y_true_clean) == 0:\n",
        "            return {'MAE': np.nan, 'RMSE': np.nan, 'MAPE': np.nan, 'Bias': np.nan}\n",
        "\n",
        "        mae = mean_absolute_error(y_true_clean, y_pred_clean)\n",
        "        rmse = np.sqrt(mean_squared_error(y_true_clean, y_pred_clean))\n",
        "\n",
        "        # MAPE - handle division by zero\n",
        "        mape = np.mean(np.abs((y_true_clean - y_pred_clean) / np.where(y_true_clean != 0, y_true_clean, 1))) * 100\n",
        "\n",
        "        # Forecast Bias\n",
        "        bias = np.mean(y_pred_clean - y_true_clean)\n",
        "\n",
        "        return {'MAE': mae, 'RMSE': rmse, 'MAPE': mape, 'Bias': bias}\n",
        "\n",
        "    def train_xgboost_grid_search(self, train_df, val_df, test_df):\n",
        "        \"\"\"Train XGBoost with comprehensive hyperparameter grid search\"\"\"\n",
        "        print(\"\\nTraining XGBoost with Grid Search (this may take a while)...\")\n",
        "\n",
        "        # Prepare features\n",
        "        X_train = train_df[self.feature_columns].fillna(0)\n",
        "        X_val = val_df[self.feature_columns].fillna(0)\n",
        "        X_test = test_df[self.feature_columns].fillna(0)\n",
        "\n",
        "        # Define hyperparameter grid\n",
        "        param_grid = {\n",
        "            'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
        "            'max_depth': [3, 4, 5, 6],\n",
        "            'n_estimators': [200, 500, 800, 1000],\n",
        "            'subsample': [0.6, 0.7, 0.8, 0.9],\n",
        "            'colsample_bytree': [0.6, 0.7, 0.8, 0.9],\n",
        "            'reg_alpha': [0, 0.1, 0.5, 1.0],\n",
        "            'reg_lambda': [1.0, 2.0, 3.0, 5.0],\n",
        "            'gamma': [0, 0.1, 0.2, 0.5],\n",
        "            'min_child_weight': [1, 3, 5, 7]\n",
        "        }\n",
        "\n",
        "        # Create parameter combinations (limit to manageable number)\n",
        "        from itertools import product\n",
        "        import random\n",
        "\n",
        "        # Generate all possible combinations\n",
        "        keys = list(param_grid.keys())\n",
        "        combinations = list(product(*[param_grid[key] for key in keys]))\n",
        "\n",
        "        # Randomly sample 50 combinations to make it manageable\n",
        "        if len(combinations) > 50:\n",
        "            combinations = random.sample(combinations, 50)\n",
        "\n",
        "        for target in self.target_columns:\n",
        "            print(f\"\\n  Grid Search for {target}...\")\n",
        "            print(f\"  Testing {len(combinations)} parameter combinations...\")\n",
        "\n",
        "            y_train = train_df[target].fillna(train_df[target].mean())\n",
        "            y_val = val_df[target].fillna(val_df[target].mean())\n",
        "            y_test = test_df[target].fillna(test_df[target].mean())\n",
        "\n",
        "            best_mae = float('inf')\n",
        "            best_params = None\n",
        "            best_model = None\n",
        "            all_results = []\n",
        "\n",
        "            for i, combo in enumerate(combinations):\n",
        "                if i % 10 == 0:\n",
        "                    print(f\"    Progress: {i}/{len(combinations)}\")\n",
        "\n",
        "                # Create parameter dictionary\n",
        "                params = dict(zip(keys, combo))\n",
        "                params.update({\n",
        "                    'objective': 'reg:squarederror',\n",
        "                    'random_state': 42,\n",
        "                    'early_stopping_rounds': 20\n",
        "                })\n",
        "\n",
        "                try:\n",
        "                    # Train model\n",
        "                    model = xgb.XGBRegressor(**params)\n",
        "                    model.fit(X_train, y_train,\n",
        "                             eval_set=[(X_val, y_val)],\n",
        "                             verbose=False)\n",
        "\n",
        "                    # Predict\n",
        "                    val_pred = model.predict(X_val)\n",
        "                    test_pred = model.predict(X_test)\n",
        "\n",
        "                    # Calculate metrics\n",
        "                    val_metrics = self.calculate_metrics(y_val.values, val_pred, 'XGBoost_GridSearch', target)\n",
        "                    test_metrics = self.calculate_metrics(y_test.values, test_pred, 'XGBoost_GridSearch', target)\n",
        "\n",
        "                    # Store results\n",
        "                    result = {\n",
        "                        'target': target,\n",
        "                        'params': params.copy(),\n",
        "                        'val_mae': val_metrics['MAE'],\n",
        "                        'val_rmse': val_metrics['RMSE'],\n",
        "                        'val_mape': val_metrics['MAPE'],\n",
        "                        'val_bias': val_metrics['Bias'],\n",
        "                        'test_mae': test_metrics['MAE'],\n",
        "                        'test_rmse': test_metrics['RMSE'],\n",
        "                        'test_mape': test_metrics['MAPE'],\n",
        "                        'test_bias': test_metrics['Bias']\n",
        "                    }\n",
        "                    all_results.append(result)\n",
        "\n",
        "                    # Check if this is the best model\n",
        "                    if val_metrics['MAE'] < best_mae:\n",
        "                        best_mae = val_metrics['MAE']\n",
        "                        best_params = params.copy()\n",
        "                        best_model = model\n",
        "                        best_val_metrics = val_metrics\n",
        "                        best_test_metrics = test_metrics\n",
        "\n",
        "                except Exception as e:\n",
        "                    continue\n",
        "\n",
        "            # Store best model and results\n",
        "            if best_model is not None:\n",
        "                model_key = f'XGBoost_GridSearch_{target}'\n",
        "                self.models[model_key] = best_model\n",
        "\n",
        "                # Save model\n",
        "                joblib.dump(best_model, f'models/{model_key}.pkl')\n",
        "\n",
        "                # Store in results\n",
        "                self.results[model_key] = {\n",
        "                    'validation': best_val_metrics,\n",
        "                    'test': best_test_metrics,\n",
        "                    'best_params': best_params\n",
        "                }\n",
        "\n",
        "                # Store hyperparameter results (only best model info)\n",
        "                self.hyperparameter_results[target] = {\n",
        "                    'best_params': best_params,\n",
        "                    'best_metrics': {\n",
        "                        'validation': best_val_metrics,\n",
        "                        'test': best_test_metrics\n",
        "                    },\n",
        "                    'total_combinations_tested': len(all_results)\n",
        "                }\n",
        "\n",
        "                print(f\"    Best MAE for {target}: {best_mae:.4f}\")\n",
        "                print(f\"    Best params: {best_params}\")\n",
        "\n",
        "        # Save best hyperparameter results only\n",
        "        import json\n",
        "        with open('results/best_hyperparameter_results.json', 'w') as f:\n",
        "            # Convert to JSON serializable format\n",
        "            json_results = {}\n",
        "            for target, data in self.hyperparameter_results.items():\n",
        "                json_results[target] = {\n",
        "                    'best_params': data['best_params'],\n",
        "                    'best_val_mae': data['best_metrics']['validation']['MAE'],\n",
        "                    'best_test_mae': data['best_metrics']['test']['MAE'],\n",
        "                    'total_combinations_tested': data['total_combinations_tested']\n",
        "                }\n",
        "            json.dump(json_results, f, indent=2)\n",
        "\n",
        "    def train_xgboost_models(self, train_df, val_df, test_df):\n",
        "        \"\"\"Train XGBoost models with default parameters (for comparison)\"\"\"\n",
        "        print(\"\\nTraining XGBoost models with default parameters...\")\n",
        "\n",
        "        # Prepare features\n",
        "        X_train = train_df[self.feature_columns].fillna(0)\n",
        "        X_val = val_df[self.feature_columns].fillna(0)\n",
        "        X_test = test_df[self.feature_columns].fillna(0)\n",
        "\n",
        "        for target in self.target_columns:\n",
        "            print(f\"  Training XGBoost for {target}...\")\n",
        "\n",
        "            y_train = train_df[target].fillna(train_df[target].mean())\n",
        "            y_val = val_df[target].fillna(val_df[target].mean())\n",
        "            y_test = test_df[target].fillna(test_df[target].mean())\n",
        "\n",
        "            # XGBoost with your friend's parameters\n",
        "            model = xgb.XGBRegressor(\n",
        "                objective='reg:squarederror',\n",
        "                random_state=42,\n",
        "                n_estimators=200,  # Increased for better performance\n",
        "                max_depth=6,\n",
        "                learning_rate=0.1,  # Slightly lower for stability\n",
        "                subsample=0.8,\n",
        "                colsample_bytree=0.8,\n",
        "                early_stopping_rounds=20  # Move to constructor\n",
        "            )\n",
        "\n",
        "            model.fit(X_train, y_train,\n",
        "                     eval_set=[(X_val, y_val)],\n",
        "                     verbose=False)\n",
        "\n",
        "            # Predictions\n",
        "            val_pred = model.predict(X_val)\n",
        "            test_pred = model.predict(X_test)\n",
        "\n",
        "            # Store model and results\n",
        "            model_key = f'XGBoost_Default_{target}'\n",
        "            self.models[model_key] = model\n",
        "\n",
        "            # Save model\n",
        "            joblib.dump(model, f'models/{model_key}.pkl')\n",
        "\n",
        "            # Calculate metrics\n",
        "            val_metrics = self.calculate_metrics(y_val.values, val_pred, 'XGBoost_Default', target)\n",
        "            test_metrics = self.calculate_metrics(y_test.values, test_pred, 'XGBoost_Default', target)\n",
        "\n",
        "            self.results[model_key] = {\n",
        "                'validation': val_metrics,\n",
        "                'test': test_metrics\n",
        "            }\n",
        "\n",
        "    def train_traditional_ml_grid_search(self, train_df, val_df, test_df):\n",
        "        \"\"\"Train traditional ML models with hyperparameter grid search\"\"\"\n",
        "        print(\"\\nTraining Traditional ML models with Grid Search...\")\n",
        "\n",
        "        X_train = train_df[self.feature_columns].fillna(0)\n",
        "        X_val = val_df[self.feature_columns].fillna(0)\n",
        "        X_test = test_df[self.feature_columns].fillna(0)\n",
        "\n",
        "        # Define hyperparameter grids for each model\n",
        "        ml_param_grids = {\n",
        "            'RandomForest': {\n",
        "                'n_estimators': [100, 200, 300, 500],\n",
        "                'max_depth': [3, 5, 10, 15, None],\n",
        "                'min_samples_split': [2, 5, 10],\n",
        "                'min_samples_leaf': [1, 2, 4],\n",
        "                'max_features': ['sqrt', 'log2', 0.5, 0.8]\n",
        "            },\n",
        "            'GradientBoosting': {\n",
        "                'n_estimators': [100, 200, 300],\n",
        "                'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
        "                'max_depth': [3, 4, 5, 6],\n",
        "                'subsample': [0.6, 0.8, 1.0],\n",
        "                'min_samples_split': [2, 5, 10]\n",
        "            },\n",
        "            'Ridge': {\n",
        "                'alpha': [0.1, 0.5, 1.0, 2.0, 5.0, 10.0, 50.0, 100.0]\n",
        "            },\n",
        "            'Lasso': {\n",
        "                'alpha': [0.01, 0.1, 0.5, 1.0, 2.0, 5.0, 10.0]\n",
        "            }\n",
        "        }\n",
        "\n",
        "        from itertools import product\n",
        "        import random\n",
        "\n",
        "        for model_name, param_grid in ml_param_grids.items():\n",
        "            print(f\"\\n  Grid Search for {model_name}...\")\n",
        "\n",
        "            # Generate parameter combinations\n",
        "            keys = list(param_grid.keys())\n",
        "            combinations = list(product(*[param_grid[key] for key in keys]))\n",
        "\n",
        "            # Limit combinations for faster execution\n",
        "            if len(combinations) > 30:\n",
        "                combinations = random.sample(combinations, 30)\n",
        "\n",
        "            for target in self.target_columns:\n",
        "                print(f\"    {model_name} for {target}...\")\n",
        "\n",
        "                y_train = train_df[target].fillna(train_df[target].mean())\n",
        "                y_val = val_df[target].fillna(val_df[target].mean())\n",
        "                y_test = test_df[target].fillna(test_df[target].mean())\n",
        "\n",
        "                best_mae = float('inf')\n",
        "                best_params = None\n",
        "                best_model = None\n",
        "\n",
        "                for combo in combinations:\n",
        "                    params = dict(zip(keys, combo))\n",
        "\n",
        "                    if model_name == 'RandomForest':\n",
        "                        params['random_state'] = 42\n",
        "                    elif model_name == 'GradientBoosting':\n",
        "                        params['random_state'] = 42\n",
        "\n",
        "                    try:\n",
        "                        # Create and train model\n",
        "                        if model_name == 'RandomForest':\n",
        "                            model = RandomForestRegressor(**params)\n",
        "                        elif model_name == 'GradientBoosting':\n",
        "                            model = GradientBoostingRegressor(**params)\n",
        "                        elif model_name == 'Ridge':\n",
        "                            model = Ridge(**params)\n",
        "                        elif model_name == 'Lasso':\n",
        "                            model = Lasso(**params)\n",
        "\n",
        "                        model.fit(X_train, y_train)\n",
        "\n",
        "                        # Predict and evaluate\n",
        "                        val_pred = model.predict(X_val)\n",
        "                        val_metrics = self.calculate_metrics(y_val.values, val_pred, model_name, target)\n",
        "\n",
        "                        if val_metrics['MAE'] < best_mae:\n",
        "                            best_mae = val_metrics['MAE']\n",
        "                            best_params = params.copy()\n",
        "                            best_model = model\n",
        "\n",
        "                    except Exception as e:\n",
        "                        continue\n",
        "\n",
        "                # Store best model\n",
        "                if best_model is not None:\n",
        "                    test_pred = best_model.predict(X_test)\n",
        "                    test_metrics = self.calculate_metrics(y_test.values, test_pred, model_name, target)\n",
        "\n",
        "                    model_key = f'{model_name}_GridSearch_{target}'\n",
        "                    self.models[model_key] = best_model\n",
        "\n",
        "                    # Save model\n",
        "                    joblib.dump(best_model, f'models/{model_key}.pkl')\n",
        "\n",
        "                    # Store results\n",
        "                    val_metrics = self.calculate_metrics(y_val.values, best_model.predict(X_val), model_name, target)\n",
        "                    self.results[model_key] = {\n",
        "                        'validation': val_metrics,\n",
        "                        'test': test_metrics,\n",
        "                        'best_params': best_params\n",
        "                    }\n",
        "\n",
        "                    print(f\"      Best MAE: {best_mae:.4f}\")\n",
        "\n",
        "    def train_deep_learning_grid_search(self, train_df, val_df, test_df):\n",
        "        \"\"\"Train deep learning models with hyperparameter grid search\"\"\"\n",
        "        try:\n",
        "            print(\"\\nTraining Deep Learning models with Grid Search...\")\n",
        "\n",
        "            # Define hyperparameter grids\n",
        "            dl_param_grids = {\n",
        "                'LSTM': {\n",
        "                    'units_1': [32, 50, 64, 100],\n",
        "                    'units_2': [25, 32, 50, 64],\n",
        "                    'dropout': [0.1, 0.2, 0.3],\n",
        "                    'batch_size': [8, 16, 32],\n",
        "                    'learning_rate': [0.001, 0.01, 0.1]\n",
        "                },\n",
        "                'GRU': {\n",
        "                    'units_1': [32, 50, 64, 100],\n",
        "                    'units_2': [25, 32, 50, 64],\n",
        "                    'dropout': [0.1, 0.2, 0.3],\n",
        "                    'batch_size': [8, 16, 32],\n",
        "                    'learning_rate': [0.001, 0.01, 0.1]\n",
        "                }\n",
        "            }\n",
        "\n",
        "            from itertools import product\n",
        "            import random\n",
        "\n",
        "            for target in self.target_columns:\n",
        "                print(f\"  Preparing sequences for {target}...\")\n",
        "\n",
        "                # Prepare sequences\n",
        "                X_train, y_train = self.prepare_lstm_data(train_df, target)\n",
        "                X_val, y_val = self.prepare_lstm_data(val_df, target)\n",
        "                X_test, y_test = self.prepare_lstm_data(test_df, target)\n",
        "\n",
        "                if len(X_train) == 0 or len(X_val) == 0:\n",
        "                    print(f\"    Insufficient data for {target}\")\n",
        "                    continue\n",
        "\n",
        "                for model_type in ['LSTM', 'GRU']:\n",
        "                    print(f\"    Grid Search for {model_type} - {target}...\")\n",
        "\n",
        "                    param_grid = dl_param_grids[model_type]\n",
        "                    keys = list(param_grid.keys())\n",
        "                    combinations = list(product(*[param_grid[key] for key in keys]))\n",
        "\n",
        "                    # Limit to 15 combinations for faster execution\n",
        "                    if len(combinations) > 15:\n",
        "                        combinations = random.sample(combinations, 15)\n",
        "\n",
        "                    best_mae = float('inf')\n",
        "                    best_params = None\n",
        "                    best_model = None\n",
        "\n",
        "                    for combo in combinations:\n",
        "                        params = dict(zip(keys, combo))\n",
        "\n",
        "                        try:\n",
        "                            # Build model\n",
        "                            model = Sequential()\n",
        "\n",
        "                            if model_type == 'LSTM':\n",
        "                                model.add(LSTM(params['units_1'], return_sequences=True,\n",
        "                                             input_shape=(X_train.shape[1], X_train.shape[2])))\n",
        "                                model.add(Dropout(params['dropout']))\n",
        "                                model.add(LSTM(params['units_2']))\n",
        "                            else:  # GRU\n",
        "                                model.add(GRU(params['units_1'], return_sequences=True,\n",
        "                                            input_shape=(X_train.shape[1], X_train.shape[2])))\n",
        "                                model.add(Dropout(params['dropout']))\n",
        "                                model.add(GRU(params['units_2']))\n",
        "\n",
        "                            model.add(Dropout(params['dropout']))\n",
        "                            model.add(Dense(25))\n",
        "                            model.add(Dense(1))\n",
        "\n",
        "                            # Compile with custom learning rate\n",
        "                            optimizer = tf.keras.optimizers.Adam(learning_rate=params['learning_rate'])\n",
        "                            model.compile(optimizer=optimizer, loss='mse')\n",
        "\n",
        "                            # Train with early stopping\n",
        "                            early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "                            model.fit(X_train, y_train,\n",
        "                                    validation_data=(X_val, y_val),\n",
        "                                    epochs=30, batch_size=params['batch_size'],\n",
        "                                    callbacks=[early_stop], verbose=0)\n",
        "\n",
        "                            # Evaluate\n",
        "                            val_pred = model.predict(X_val, verbose=0).flatten()\n",
        "                            val_metrics = self.calculate_metrics(y_val, val_pred, model_type, target)\n",
        "\n",
        "                            if val_metrics['MAE'] < best_mae:\n",
        "                                best_mae = val_metrics['MAE']\n",
        "                                best_params = params.copy()\n",
        "                                best_model = model\n",
        "\n",
        "                        except Exception as e:\n",
        "                            continue\n",
        "\n",
        "                    # Store best model\n",
        "                    if best_model is not None:\n",
        "                        test_pred = best_model.predict(X_test, verbose=0).flatten()\n",
        "                        test_metrics = self.calculate_metrics(y_test, test_pred, model_type, target)\n",
        "\n",
        "                        model_key = f'{model_type}_GridSearch_{target}'\n",
        "                        self.models[model_key] = best_model\n",
        "\n",
        "                        # Save model\n",
        "                        best_model.save(f'models/{model_key}.h5')\n",
        "\n",
        "                        # Store results\n",
        "                        val_metrics = self.calculate_metrics(y_val, best_model.predict(X_val, verbose=0).flatten(), model_type, target)\n",
        "                        self.results[model_key] = {\n",
        "                            'validation': val_metrics,\n",
        "                            'test': test_metrics,\n",
        "                            'best_params': best_params\n",
        "                        }\n",
        "\n",
        "                        print(f\"      Best MAE: {best_mae:.4f}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error in deep learning grid search: {e}\")\n",
        "\n",
        "    def train_traditional_ml_models(self, train_df, val_df, test_df):\n",
        "        \"\"\"Train traditional ML models with default parameters (for comparison)\"\"\"\n",
        "        print(\"\\nTraining traditional ML models with default parameters...\")\n",
        "\n",
        "        X_train = train_df[self.feature_columns].fillna(0)\n",
        "        X_val = val_df[self.feature_columns].fillna(0)\n",
        "        X_test = test_df[self.feature_columns].fillna(0)\n",
        "\n",
        "        # Define models to try\n",
        "        ml_models = {\n",
        "            'RandomForest_Default': RandomForestRegressor(n_estimators=100, random_state=42, max_depth=10),\n",
        "            'GradientBoosting_Default': GradientBoostingRegressor(n_estimators=100, random_state=42, max_depth=6),\n",
        "            'Ridge_Default': Ridge(alpha=1.0),\n",
        "            'Lasso_Default': Lasso(alpha=1.0),\n",
        "            'LinearRegression_Default': LinearRegression()\n",
        "        }\n",
        "\n",
        "        for model_name, model in ml_models.items():\n",
        "            for target in self.target_columns:\n",
        "                print(f\"  Training {model_name} for {target}...\")\n",
        "\n",
        "                y_train = train_df[target].fillna(train_df[target].mean())\n",
        "                y_val = val_df[target].fillna(val_df[target].mean())\n",
        "                y_test = test_df[target].fillna(test_df[target].mean())\n",
        "\n",
        "                # Train model\n",
        "                model.fit(X_train, y_train)\n",
        "\n",
        "                # Predictions\n",
        "                val_pred = model.predict(X_val)\n",
        "                test_pred = model.predict(X_test)\n",
        "\n",
        "                # Store model and results\n",
        "                model_key = f'{model_name}_{target}'\n",
        "                self.models[model_key] = model\n",
        "\n",
        "                # Save model\n",
        "                joblib.dump(model, f'models/{model_key}.pkl')\n",
        "\n",
        "                # Calculate metrics\n",
        "                val_metrics = self.calculate_metrics(y_val.values, val_pred, model_name, target)\n",
        "                test_metrics = self.calculate_metrics(y_test.values, test_pred, model_name, target)\n",
        "\n",
        "                self.results[model_key] = {\n",
        "                    'validation': val_metrics,\n",
        "                    'test': test_metrics\n",
        "                }\n",
        "\n",
        "    def prepare_lstm_data(self, df, target_col, sequence_length=7):\n",
        "        \"\"\"Prepare data for LSTM/GRU models\"\"\"\n",
        "        sequences = []\n",
        "        targets = []\n",
        "\n",
        "        for unique_id in df['unique_id'].unique():\n",
        "            group_data = df[df['unique_id'] == unique_id].sort_values('date')\n",
        "\n",
        "            # Use a subset of features for LSTM to avoid overfitting\n",
        "            lstm_features = ['dayofweek', 'month', 'is_weekend'] + \\\n",
        "                           [col for col in self.feature_columns if ('lag_' in col or 'roll_mean_' in col) and col in self.feature_columns]\n",
        "            lstm_features = [col for col in lstm_features if col in group_data.columns][:10]  # Limit features\n",
        "\n",
        "            X = group_data[lstm_features].fillna(0).values\n",
        "            y = group_data[target_col].fillna(group_data[target_col].mean()).values\n",
        "\n",
        "            for i in range(sequence_length, len(X)):\n",
        "                sequences.append(X[i-sequence_length:i])\n",
        "                targets.append(y[i])\n",
        "\n",
        "        return np.array(sequences), np.array(targets)\n",
        "\n",
        "    def train_deep_learning_models(self, train_df, val_df, test_df):\n",
        "        \"\"\"Train LSTM and GRU models\"\"\"\n",
        "        try:\n",
        "            print(\"\\nTraining Deep Learning models...\")\n",
        "\n",
        "            for target in self.target_columns:\n",
        "                print(f\"  Preparing data for {target}...\")\n",
        "\n",
        "                # Prepare sequences\n",
        "                X_train, y_train = self.prepare_lstm_data(train_df, target)\n",
        "                X_val, y_val = self.prepare_lstm_data(val_df, target)\n",
        "                X_test, y_test = self.prepare_lstm_data(test_df, target)\n",
        "\n",
        "                if len(X_train) == 0 or len(X_val) == 0 or len(X_test) == 0:\n",
        "                    print(f\"    Insufficient data for {target}, skipping deep learning models\")\n",
        "                    continue\n",
        "\n",
        "                # LSTM Model\n",
        "                print(f\"    Training LSTM for {target}...\")\n",
        "                lstm_model = Sequential([\n",
        "                    LSTM(50, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])),\n",
        "                    Dropout(0.2),\n",
        "                    LSTM(50),\n",
        "                    Dropout(0.2),\n",
        "                    Dense(25),\n",
        "                    Dense(1)\n",
        "                ])\n",
        "\n",
        "                lstm_model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "                early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "                lstm_model.fit(X_train, y_train,\n",
        "                              validation_data=(X_val, y_val),\n",
        "                              epochs=50, batch_size=16,\n",
        "                              callbacks=[early_stop], verbose=0)\n",
        "\n",
        "                # LSTM Predictions\n",
        "                val_pred_lstm = lstm_model.predict(X_val, verbose=0).flatten()\n",
        "                test_pred_lstm = lstm_model.predict(X_test, verbose=0).flatten()\n",
        "\n",
        "                # Store LSTM results\n",
        "                model_key = f'LSTM_{target}'\n",
        "                self.models[model_key] = lstm_model\n",
        "                lstm_model.save(f'models/{model_key}.h5')\n",
        "\n",
        "                val_metrics = self.calculate_metrics(y_val, val_pred_lstm, 'LSTM', target)\n",
        "                test_metrics = self.calculate_metrics(y_test, test_pred_lstm, 'LSTM', target)\n",
        "\n",
        "                self.results[model_key] = {\n",
        "                    'validation': val_metrics,\n",
        "                    'test': test_metrics\n",
        "                }\n",
        "\n",
        "                # GRU Model\n",
        "                print(f\"    Training GRU for {target}...\")\n",
        "                gru_model = Sequential([\n",
        "                    GRU(50, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])),\n",
        "                    Dropout(0.2),\n",
        "                    GRU(50),\n",
        "                    Dropout(0.2),\n",
        "                    Dense(25),\n",
        "                    Dense(1)\n",
        "                ])\n",
        "\n",
        "                gru_model.compile(optimizer='adam', loss='mse')\n",
        "                gru_model.fit(X_train, y_train,\n",
        "                             validation_data=(X_val, y_val),\n",
        "                             epochs=50, batch_size=16,\n",
        "                             callbacks=[early_stop], verbose=0)\n",
        "\n",
        "                # GRU Predictions\n",
        "                val_pred_gru = gru_model.predict(X_val, verbose=0).flatten()\n",
        "                test_pred_gru = gru_model.predict(X_test, verbose=0).flatten()\n",
        "\n",
        "                # Store GRU results\n",
        "                model_key = f'GRU_{target}'\n",
        "                self.models[model_key] = gru_model\n",
        "                gru_model.save(f'models/{model_key}.h5')\n",
        "\n",
        "                val_metrics = self.calculate_metrics(y_val, val_pred_gru, 'GRU', target)\n",
        "                test_metrics = self.calculate_metrics(y_test, test_pred_gru, 'GRU', target)\n",
        "\n",
        "                self.results[model_key] = {\n",
        "                    'validation': val_metrics,\n",
        "                    'test': test_metrics\n",
        "                }\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error in deep learning training: {e}\")\n",
        "\n",
        "    def train_time_series_models(self, train_df, val_df, test_df):\n",
        "        \"\"\"Train ARIMA models - aggregate approach for each target\"\"\"\n",
        "        try:\n",
        "            print(\"\\nTraining Time Series models...\")\n",
        "\n",
        "            for target in self.target_columns:\n",
        "                print(f\"  Training ARIMA for {target}...\")\n",
        "\n",
        "                # Aggregate all time series data for this target\n",
        "                all_train_data = []\n",
        "                all_val_data = []\n",
        "                all_test_data = []\n",
        "\n",
        "                for unique_id in train_df['unique_id'].unique():\n",
        "                    # Get time series for this group\n",
        "                    train_ts = train_df[train_df['unique_id'] == unique_id][target].fillna(method='ffill')\n",
        "                    val_ts = val_df[val_df['unique_id'] == unique_id][target].fillna(method='ffill')\n",
        "                    test_ts = test_df[test_df['unique_id'] == unique_id][target].fillna(method='ffill')\n",
        "\n",
        "                    if len(train_ts) >= 5:  # Minimum data requirement\n",
        "                        all_train_data.extend(train_ts.values)\n",
        "                        all_val_data.extend(val_ts.values)\n",
        "                        all_test_data.extend(test_ts.values)\n",
        "\n",
        "                if len(all_train_data) < 20:  # Need sufficient data for ARIMA\n",
        "                    print(f\"    Insufficient data for ARIMA {target}, skipping...\")\n",
        "                    continue\n",
        "\n",
        "                # Convert to pandas Series\n",
        "                train_series = pd.Series(all_train_data)\n",
        "                val_series = pd.Series(all_val_data)\n",
        "                test_series = pd.Series(all_test_data)\n",
        "\n",
        "                # Try different ARIMA orders and select best\n",
        "                arima_orders = [(1,1,1), (2,1,1), (1,1,2), (2,1,2), (0,1,1), (1,0,1)]\n",
        "                best_aic = float('inf')\n",
        "                best_model = None\n",
        "                best_order = None\n",
        "\n",
        "                for order in arima_orders:\n",
        "                    try:\n",
        "                        arima_model = ARIMA(train_series, order=order)\n",
        "                        arima_fitted = arima_model.fit()\n",
        "\n",
        "                        if arima_fitted.aic < best_aic:\n",
        "                            best_aic = arima_fitted.aic\n",
        "                            best_model = arima_fitted\n",
        "                            best_order = order\n",
        "                    except:\n",
        "                        continue\n",
        "\n",
        "                if best_model is not None:\n",
        "                    try:\n",
        "                        # Forecast\n",
        "                        val_forecast = best_model.forecast(steps=len(val_series))\n",
        "                        test_forecast = best_model.forecast(steps=len(test_series))\n",
        "\n",
        "                        # Store model\n",
        "                        model_key = f'ARIMA_{target}'\n",
        "                        self.models[model_key] = best_model\n",
        "\n",
        "                        # Save model\n",
        "                        with open(f'models/{model_key}.pkl', 'wb') as f:\n",
        "                            pickle.dump(best_model, f)\n",
        "\n",
        "                        # Calculate metrics\n",
        "                        val_metrics = self.calculate_metrics(val_series.values, val_forecast, 'ARIMA', target)\n",
        "                        test_metrics = self.calculate_metrics(test_series.values, test_forecast, 'ARIMA', target)\n",
        "\n",
        "                        self.results[model_key] = {\n",
        "                            'validation': val_metrics,\n",
        "                            'test': test_metrics,\n",
        "                            'best_params': {'order': best_order, 'aic': best_aic}\n",
        "                        }\n",
        "\n",
        "                        print(f\"    ARIMA {target} - Best order: {best_order}, AIC: {best_aic:.2f}\")\n",
        "\n",
        "                    except Exception as e:\n",
        "                        print(f\"    ARIMA forecasting failed for {target}: {e}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error in time series training: {e}\")\n",
        "\n",
        "    def create_comparison_table(self):\n",
        "        \"\"\"Create comparison table of all models\"\"\"\n",
        "        print(\"\\nCreating comparison table...\")\n",
        "\n",
        "        comparison_data = []\n",
        "\n",
        "        for model_key, metrics in self.results.items():\n",
        "            # Better parsing of model name and target\n",
        "            if model_key.count('_') >= 2:\n",
        "                # Handle cases like 'XGBoost_GridSearch_usage_cpu'\n",
        "                parts = model_key.split('_')\n",
        "                if len(parts) >= 3:\n",
        "                    # Find target (should be one of our target columns)\n",
        "                    target = None\n",
        "                    for i in range(len(parts)-1, 0, -1):\n",
        "                        potential_target = '_'.join(parts[i:])\n",
        "                        if potential_target in self.target_columns:\n",
        "                            target = potential_target\n",
        "                            model_name = '_'.join(parts[:i])\n",
        "                            break\n",
        "\n",
        "                    if target is None:\n",
        "                        # Fallback to original method\n",
        "                        model_name, target = model_key.rsplit('_', 1)\n",
        "                else:\n",
        "                    model_name, target = model_key.rsplit('_', 1)\n",
        "            else:\n",
        "                model_name, target = model_key.rsplit('_', 1)\n",
        "\n",
        "            if 'validation' in metrics and 'test' in metrics:\n",
        "                row = {\n",
        "                    'Model': model_name,\n",
        "                    'Target': target,\n",
        "                    'Val_MAE': metrics['validation']['MAE'],\n",
        "                    'Val_RMSE': metrics['validation']['RMSE'],\n",
        "                    'Val_MAPE': metrics['validation']['MAPE'],\n",
        "                    'Val_Bias': metrics['validation']['Bias'],\n",
        "                    'Test_MAE': metrics['test']['MAE'],\n",
        "                    'Test_RMSE': metrics['test']['RMSE'],\n",
        "                    'Test_MAPE': metrics['test']['MAPE'],\n",
        "                    'Test_Bias': metrics['test']['Bias']\n",
        "                }\n",
        "\n",
        "                # Add hyperparameters if available\n",
        "                if 'best_params' in metrics:\n",
        "                    # Convert params to string for display\n",
        "                    params_str = str(metrics['best_params'])[:100] + \"...\" if len(str(metrics['best_params'])) > 100 else str(metrics['best_params'])\n",
        "                    row['Hyperparameters'] = params_str\n",
        "                else:\n",
        "                    row['Hyperparameters'] = 'Default'\n",
        "\n",
        "                comparison_data.append(row)\n",
        "\n",
        "        comparison_df = pd.DataFrame(comparison_data)\n",
        "        comparison_df = comparison_df.round(4)\n",
        "\n",
        "        # Save comparison table\n",
        "        comparison_df.to_csv('results/model_comparison.csv', index=False)\n",
        "\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"MODEL COMPARISON TABLE\")\n",
        "        print(\"=\"*80)\n",
        "        print(comparison_df.to_string(index=False))\n",
        "\n",
        "        return comparison_df\n",
        "\n",
        "    def get_top_models_summary(self, comparison_df):\n",
        "        \"\"\"Get top 1 model for each target with detailed info\"\"\"\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"TOP 1 MODEL FOR EACH TARGET\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        top_models_data = []\n",
        "\n",
        "        for target in self.target_columns:\n",
        "            target_results = comparison_df[comparison_df['Target'] == target].copy()\n",
        "\n",
        "            if len(target_results) > 0:\n",
        "                # Find best model based on validation MAE\n",
        "                best_idx = target_results['Val_MAE'].idxmin()\n",
        "                best_row = target_results.loc[best_idx]\n",
        "\n",
        "                model_name = best_row['Model']\n",
        "\n",
        "                # Reconstruct model key properly\n",
        "                model_key = f\"{model_name}_{target}\"\n",
        "\n",
        "                # Get parameters if available\n",
        "                params = \"Default\"\n",
        "                if 'Hyperparameters' in best_row and pd.notna(best_row['Hyperparameters']):\n",
        "                    params = best_row['Hyperparameters']\n",
        "                elif model_key in self.results and 'best_params' in self.results[model_key]:\n",
        "                    params = str(self.results[model_key]['best_params'])\n",
        "                elif target in self.hyperparameter_results:\n",
        "                    params = str(self.hyperparameter_results[target]['best_params'])\n",
        "\n",
        "                top_model_info = {\n",
        "                    'Target': target,\n",
        "                    'Best_Model': model_name,\n",
        "                    'Val_MAE': best_row['Val_MAE'],\n",
        "                    'Val_RMSE': best_row['Val_RMSE'],\n",
        "                    'Val_MAPE': best_row['Val_MAPE'],\n",
        "                    'Val_Bias': best_row['Val_Bias'],\n",
        "                    'Test_MAE': best_row['Test_MAE'],\n",
        "                    'Test_RMSE': best_row['Test_RMSE'],\n",
        "                    'Test_MAPE': best_row['Test_MAPE'],\n",
        "                    'Test_Bias': best_row['Test_Bias'],\n",
        "                    'Hyperparameters': params\n",
        "                }\n",
        "\n",
        "                top_models_data.append(top_model_info)\n",
        "\n",
        "                # Copy best model to top_models directory\n",
        "                try:\n",
        "                    import shutil\n",
        "                    # Try different file extensions\n",
        "                    for ext in ['.pkl', '.h5']:\n",
        "                        source_file = f'models/{model_key}{ext}'\n",
        "                        if os.path.exists(source_file):\n",
        "                            dest_file = f'top_models/{target}_best_model{ext}'\n",
        "                            shutil.copy2(source_file, dest_file)\n",
        "                            print(f\" Moved {model_name} for {target} to top_models/\")\n",
        "                            break\n",
        "                    else:\n",
        "                        print(f\"  Model file not found for {model_key}\")\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"  Could not copy model for {target}: {e}\")\n",
        "\n",
        "        # Create DataFrame and save\n",
        "        if top_models_data:\n",
        "            top_models_df = pd.DataFrame(top_models_data)\n",
        "            top_models_df = top_models_df.round(4)\n",
        "\n",
        "            # Save to CSV\n",
        "            top_models_df.to_csv('results/top_models_summary.csv', index=False)\n",
        "\n",
        "            print(\"\\n\" + \"=\"*60)\n",
        "            print(\"TOP MODELS SUMMARY\")\n",
        "            print(\"=\"*60)\n",
        "            print(top_models_df.to_string(index=False))\n",
        "        else:\n",
        "            print(\"No top models found!\")\n",
        "            top_models_df = pd.DataFrame()\n",
        "\n",
        "        return top_models_df\n",
        "\n",
        "    def run_complete_pipeline(self):\n",
        "        \"\"\"Run the complete ML pipeline\"\"\"\n",
        "        print(\"=\"*80)\n",
        "        print(\"STARTING COMPLETE ML FORECASTING PIPELINE\")\n",
        "        print(\"=\"*80)\n",
        "\n",
        "        # Load data\n",
        "        df = self.load_and_prepare_data()\n",
        "\n",
        "        # Create splits\n",
        "        train_df, val_df, test_df = self.create_train_val_test_split(df)\n",
        "\n",
        "        # Train all models\n",
        "        self.train_xgboost_grid_search(train_df, val_df, test_df)  # Grid search first\n",
        "        self.train_xgboost_models(train_df, val_df, test_df)       # Default params for comparison\n",
        "        self.train_traditional_ml_models(train_df, val_df, test_df)\n",
        "        self.train_deep_learning_models(train_df, val_df, test_df)\n",
        "        self.train_time_series_models(train_df, val_df, test_df)\n",
        "\n",
        "        # Create comparison table\n",
        "        comparison_df = self.create_comparison_table()\n",
        "\n",
        "        # Get top models summary\n",
        "        top_models_df = self.get_top_models_summary(comparison_df)\n",
        "\n",
        "        print(f\"\\n Pipeline complete! All models saved in 'models/' directory\")\n",
        "        print(f\" Top models moved to 'top_models/' directory\")\n",
        "        print(f\" Results saved in 'results/' directory\")\n",
        "\n",
        "        return comparison_df, top_models_df\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6AyA5_GQu1iW",
        "outputId": "c29344b3-85cb-4f7a-b4af-a82bb44776de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "STARTING COMPLETE ML FORECASTING PIPELINE\n",
            "================================================================================\n",
            "Loading and preparing data...\n",
            "Data loaded: (1080, 52)\n",
            "Feature columns: 47\n",
            "Target columns: ['usage_cpu', 'usage_storage', 'users_active']\n",
            "Train: 744 samples\n",
            "Validation: 216 samples\n",
            "Test: 120 samples\n",
            "\n",
            "Training XGBoost with Grid Search (this may take a while)...\n",
            "\n",
            "  Grid Search for usage_cpu...\n",
            "  Testing 50 parameter combinations...\n",
            "    Progress: 0/50\n",
            "    Progress: 10/50\n",
            "    Progress: 20/50\n",
            "    Progress: 30/50\n",
            "    Progress: 40/50\n",
            "    Best MAE for usage_cpu: 12.3551\n",
            "    Best params: {'learning_rate': 0.2, 'max_depth': 5, 'n_estimators': 800, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.5, 'reg_lambda': 5.0, 'gamma': 0.1, 'min_child_weight': 5, 'objective': 'reg:squarederror', 'random_state': 42, 'early_stopping_rounds': 20}\n",
            "\n",
            "  Grid Search for usage_storage...\n",
            "  Testing 50 parameter combinations...\n",
            "    Progress: 0/50\n",
            "    Progress: 10/50\n",
            "    Progress: 20/50\n",
            "    Progress: 30/50\n",
            "    Progress: 40/50\n",
            "    Best MAE for usage_storage: 9.6439\n",
            "    Best params: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 500, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 3.0, 'gamma': 0.5, 'min_child_weight': 7, 'objective': 'reg:squarederror', 'random_state': 42, 'early_stopping_rounds': 20}\n",
            "\n",
            "  Grid Search for users_active...\n",
            "  Testing 50 parameter combinations...\n",
            "    Progress: 0/50\n",
            "    Progress: 10/50\n",
            "    Progress: 20/50\n",
            "    Progress: 30/50\n",
            "    Progress: 40/50\n",
            "    Best MAE for users_active: 72.0594\n",
            "    Best params: {'learning_rate': 0.2, 'max_depth': 4, 'n_estimators': 1000, 'subsample': 0.8, 'colsample_bytree': 0.6, 'reg_alpha': 1.0, 'reg_lambda': 2.0, 'gamma': 0, 'min_child_weight': 5, 'objective': 'reg:squarederror', 'random_state': 42, 'early_stopping_rounds': 20}\n",
            "\n",
            "Training XGBoost models with default parameters...\n",
            "  Training XGBoost for usage_cpu...\n",
            "  Training XGBoost for usage_storage...\n",
            "  Training XGBoost for users_active...\n",
            "\n",
            "Training traditional ML models with default parameters...\n",
            "  Training RandomForest_Default for usage_cpu...\n",
            "  Training RandomForest_Default for usage_storage...\n",
            "  Training RandomForest_Default for users_active...\n",
            "  Training GradientBoosting_Default for usage_cpu...\n",
            "  Training GradientBoosting_Default for usage_storage...\n",
            "  Training GradientBoosting_Default for users_active...\n",
            "  Training Ridge_Default for usage_cpu...\n",
            "  Training Ridge_Default for usage_storage...\n",
            "  Training Ridge_Default for users_active...\n",
            "  Training Lasso_Default for usage_cpu...\n",
            "  Training Lasso_Default for usage_storage...\n",
            "  Training Lasso_Default for users_active...\n",
            "  Training LinearRegression_Default for usage_cpu...\n",
            "  Training LinearRegression_Default for usage_storage...\n",
            "  Training LinearRegression_Default for users_active...\n",
            "\n",
            "Training Deep Learning models...\n",
            "  Preparing data for usage_cpu...\n",
            "    Training LSTM for usage_cpu...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    Training GRU for usage_cpu...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Preparing data for usage_storage...\n",
            "    Training LSTM for usage_storage...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    Training GRU for usage_storage...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Preparing data for users_active...\n",
            "    Training LSTM for users_active...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    Training GRU for users_active...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training Time Series models...\n",
            "  Training ARIMA for usage_cpu...\n",
            "    ARIMA usage_cpu - Best order: (0, 1, 1), AIC: 6100.94\n",
            "  Training ARIMA for usage_storage...\n",
            "    ARIMA usage_storage - Best order: (0, 1, 1), AIC: 11155.09\n",
            "  Training ARIMA for users_active...\n",
            "    ARIMA users_active - Best order: (0, 1, 1), AIC: 8755.76\n",
            "\n",
            "Creating comparison table...\n",
            "\n",
            "================================================================================\n",
            "MODEL COMPARISON TABLE\n",
            "================================================================================\n",
            "                   Model        Target  Val_MAE  Val_RMSE  Val_MAPE  Val_Bias  Test_MAE  Test_RMSE  Test_MAPE  Test_Bias                                                                                         Hyperparameters\n",
            "      XGBoost_GridSearch     usage_cpu  12.3551   14.1620   17.8297    1.4082   12.4506    14.6107    18.2209     0.9505 {'learning_rate': 0.2, 'max_depth': 5, 'n_estimators': 800, 'subsample': 0.7, 'colsample_bytree': 0....\n",
            "      XGBoost_GridSearch usage_storage   9.6439   12.4008    0.9151   -0.0024   10.9121    14.3216     0.9917    -2.3178 {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 500, 'subsample': 0.7, 'colsample_bytree': 0....\n",
            "      XGBoost_GridSearch  users_active  72.0594   83.6200   23.4052    6.0291   73.7700    84.8760    21.9844   -10.9678 {'learning_rate': 0.2, 'max_depth': 4, 'n_estimators': 1000, 'subsample': 0.8, 'colsample_bytree': 0...\n",
            "         XGBoost_Default     usage_cpu  12.4696   14.2920   17.8736    0.9129   12.6098    14.6552    18.5340     1.2843                                                                                                 Default\n",
            "         XGBoost_Default usage_storage  42.7923   54.9680    4.0825   -3.8307   38.7098    48.2090     3.7038     0.4958                                                                                                 Default\n",
            "         XGBoost_Default  users_active  72.6050   83.9647   23.5307    5.3627   73.9682    85.5573    22.0528   -11.3219                                                                                                 Default\n",
            "    RandomForest_Default     usage_cpu  12.4818   14.3469   17.8385    0.7737   13.0739    15.0306    19.1225     0.9708                                                                                                 Default\n",
            "    RandomForest_Default usage_storage   7.4245    9.4693    0.6324   -0.7641    6.9360     8.9293     0.5763     0.0298                                                                                                 Default\n",
            "    RandomForest_Default  users_active  75.0782   87.4523   24.7442   11.6673   74.1471    85.5229    22.2959    -7.7081                                                                                                 Default\n",
            "GradientBoosting_Default     usage_cpu  13.3733   15.5952   19.0810    0.5549   13.7892    15.9298    19.9300     0.8592                                                                                                 Default\n",
            "GradientBoosting_Default usage_storage   4.2466    5.7422    0.3770   -0.0852    4.0338     5.1835     0.3458     0.5230                                                                                                 Default\n",
            "GradientBoosting_Default  users_active  79.2394   93.5584   26.1104   13.2723   80.3991    96.2176    24.4744    -4.2446                                                                                                 Default\n",
            "           Ridge_Default     usage_cpu  13.1296   15.3232   18.8349    1.1861   13.0600    15.1155    18.9343     0.1864                                                                                                 Default\n",
            "           Ridge_Default usage_storage   2.2151    3.0747    0.2254   -0.3464    2.4011     3.5597     0.2323    -0.8433                                                                                                 Default\n",
            "           Ridge_Default  users_active  74.4058   88.3426   24.8715   17.6470   72.5322    85.1943    22.2148    -4.0949                                                                                                 Default\n",
            "           Lasso_Default     usage_cpu  12.6505   14.6634   18.2201    1.2947   12.6379    14.7174    18.3412     0.2427                                                                                                 Default\n",
            "           Lasso_Default usage_storage   2.1449    3.0102    0.2159   -0.2805    2.3226     3.3754     0.2251    -0.5567                                                                                                 Default\n",
            "           Lasso_Default  users_active  74.6358   88.2024   24.9900   18.8290   72.6930    84.6597    22.2783    -2.7712                                                                                                 Default\n",
            "LinearRegression_Default     usage_cpu  13.1516   15.3721   18.8634    1.1794   13.0558    15.1243    18.9402     0.2464                                                                                                 Default\n",
            "LinearRegression_Default usage_storage   2.2215    3.0790    0.2260   -0.3609    2.4115     3.5783     0.2331    -0.8782                                                                                                 Default\n",
            "LinearRegression_Default  users_active  74.1497   87.9432   24.7702   16.9084   72.3512    85.1362    22.1379    -4.5256                                                                                                 Default\n",
            "                    LSTM     usage_cpu  12.9712   14.7635   18.2797    0.0201   14.8574    16.6909    20.9792    -1.2568                                                                                                 Default\n",
            "                     GRU     usage_cpu  12.9773   14.7625   18.2728   -0.0289   14.8461    16.6802    20.9503    -1.2955                                                                                                 Default\n",
            "                    LSTM usage_storage 357.6255  420.3871   35.6698    1.2050  380.5428   432.6778    41.3445    72.5415                                                                                                 Default\n",
            "                     GRU usage_storage 357.5876  420.3867   35.6518    0.6961  380.4296   432.5925    41.3179    72.0322                                                                                                 Default\n",
            "                    LSTM  users_active  72.3034   83.3335   23.1415    2.0542   67.9025    78.9979    19.9564   -10.2178                                                                                                 Default\n",
            "                     GRU  users_active  72.2130   83.3224   22.8723   -1.5935   68.3248    79.5525    19.8685   -13.8655                                                                                                 Default\n",
            "                   ARIMA     usage_cpu  12.5002   14.3213   17.6012   -0.4925   12.5333    14.6113    18.2088     0.4269                                              {'order': (0, 1, 1), 'aic': np.float64(6100.941599867423)}\n",
            "                   ARIMA usage_storage 357.8827  420.1518   37.6771   73.0061  374.0881   432.0560    37.5975    32.2542                                             {'order': (0, 1, 1), 'aic': np.float64(11155.089352792778)}\n",
            "                   ARIMA  users_active  72.9208   84.4866   23.6396    5.1855   73.2935    84.8909    21.9029   -11.2302                                              {'order': (0, 1, 1), 'aic': np.float64(8755.755714225117)}\n",
            "\n",
            "============================================================\n",
            "TOP 1 MODEL FOR EACH TARGET\n",
            "============================================================\n",
            " Moved XGBoost_GridSearch for usage_cpu to top_models/\n",
            " Moved Lasso_Default for usage_storage to top_models/\n",
            " Moved XGBoost_GridSearch for users_active to top_models/\n",
            "\n",
            "============================================================\n",
            "TOP MODELS SUMMARY\n",
            "============================================================\n",
            "       Target         Best_Model  Val_MAE  Val_RMSE  Val_MAPE  Val_Bias  Test_MAE  Test_RMSE  Test_MAPE  Test_Bias                                                                                         Hyperparameters\n",
            "    usage_cpu XGBoost_GridSearch  12.3551   14.1620   17.8297    1.4082   12.4506    14.6107    18.2209     0.9505 {'learning_rate': 0.2, 'max_depth': 5, 'n_estimators': 800, 'subsample': 0.7, 'colsample_bytree': 0....\n",
            "usage_storage      Lasso_Default   2.1449    3.0102    0.2159   -0.2805    2.3226     3.3754     0.2251    -0.5567                                                                                                 Default\n",
            " users_active XGBoost_GridSearch  72.0594   83.6200   23.4052    6.0291   73.7700    84.8760    21.9844   -10.9678 {'learning_rate': 0.2, 'max_depth': 4, 'n_estimators': 1000, 'subsample': 0.8, 'colsample_bytree': 0...\n",
            "\n",
            " Pipeline complete! All models saved in 'models/' directory\n",
            " Top models moved to 'top_models/' directory\n",
            " Results saved in 'results/' directory\n",
            "\n",
            "================================================================================\n",
            "PIPELINE EXECUTION COMPLETED SUCCESSFULLY!\n",
            "================================================================================\n",
            " Total models trained: 30\n",
            " Best models identified for 3 targets\n",
            " All results saved in 'results/' directory\n",
            " Best models saved in 'top_models/' directory\n"
          ]
        }
      ],
      "source": [
        "\n",
        "pipeline = ForecastingPipeline('/content/enhanced_features.csv')  # Replace with your actual data file path\n",
        "\n",
        "# Run complete pipeline\n",
        "comparison_df, top_models_df = pipeline.run_complete_pipeline()\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"PIPELINE EXECUTION COMPLETED SUCCESSFULLY!\")\n",
        "print(\"=\"*80)\n",
        "print(f\" Total models trained: {len(pipeline.results)}\")\n",
        "print(f\" Best models identified for {len(top_models_df)} targets\")\n",
        "print(f\" All results saved in 'results/' directory\")\n",
        "print(f\" Best models saved in 'top_models/' directory\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "myenv (3.13.3)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
